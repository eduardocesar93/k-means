{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_de_guitarra(center_x, center_y, sigma):\n",
    "    return np.random.multivariate_normal([center_x, center_y], [[sigma, 0], [0, sigma]], 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_simulation(sigma):\n",
    "    points = []\n",
    "    for i in range(1000):\n",
    "        x = random.randrange(4)\n",
    "        if (x == 0):\n",
    "            points.append(sample_de_guitarra(1, 0, sigma))\n",
    "        elif (x == 1):\n",
    "            points.append(sample_de_guitarra(0, -1, sigma))\n",
    "        elif (x == 2):\n",
    "            points.append(sample_de_guitarra(-1, 0, sigma))\n",
    "        else:\n",
    "            points.append(sample_de_guitarra(0, 1, sigma))\n",
    "    return points\n",
    "\n",
    "def data_uniform(min_x, max_x, min_y, max_y):\n",
    "    points = []\n",
    "    for i in range(1000):\n",
    "        x = random.uniform(min_x, max_x)\n",
    "        y = random.uniform(min_y, max_y)\n",
    "        points.append([x, y])\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def objective_value(num_cluster, points):\n",
    "    kmeans = KMeans(n_clusters=num_cluster).fit(points)\n",
    "    return -kmeans.score(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = data_simulation(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_simulation = []\n",
    "ks = [i + 1 for i in range(20)]\n",
    "for i in ks:\n",
    "    results_simulation.append(objective_value(i, points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"K-Means in 4 Gaussian Distribuition\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"\")\n",
    "plt.plot(ks, results_simulation, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_results = []\n",
    "for j in range(100):\n",
    "    points = data_simulation(0.5)\n",
    "    x_min = min([a[0] for a in points])\n",
    "    x_max = max([a[0] for a in points])\n",
    "    y_min = min([a[1] for a in points])\n",
    "    y_max = max([a[1] for a in points])\n",
    "    points_uniform = data_uniform(x_min, x_max, y_min, y_max)\n",
    "    results = []\n",
    "    ks = [i + 1 for i in range(20)]\n",
    "    for i in ks:\n",
    "        results.append(objective_value(i, points_uniform))\n",
    "    total_results.append(results)\n",
    "sum_results = [0] * len(total_results[0])\n",
    "for i in range(len(total_results)):\n",
    "    for j in range(len(total_results[0])):\n",
    "        sum_results[j] += total_results[i][j]\n",
    "for i in range(len(total_results[0])):\n",
    "    sum_results[i] /= len(total_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"K-Means in Uniform Distribuition\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"\")\n",
    "plt.plot(ks, sum_results, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_K = [math.log(sum_results[i]) - math.log(results_simulation[i]) for i in range(len(results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"Gap statistic - sigma = 0.15\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"\")\n",
    "plt.plot(ks, G_K, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maximum_k(sigma):\n",
    "    points = data_simulation(sigma)\n",
    "    results_simulation = []\n",
    "    ks = [i + 1 for i in range(20)]\n",
    "    for i in ks:\n",
    "        results_simulation.append(objective_value(i, points))\n",
    "    total_results = []\n",
    "    for j in range(40):\n",
    "        points = data_simulation(sigma)\n",
    "        x_min = min([a[0] for a in points])\n",
    "        x_max = max([a[0] for a in points])\n",
    "        y_min = min([a[1] for a in points])\n",
    "        y_max = max([a[1] for a in points])\n",
    "        points_uniform = data_uniform(x_min, x_max, y_min, y_max)\n",
    "        results = []\n",
    "        for i in ks:\n",
    "            results.append(objective_value(i, points_uniform))\n",
    "        total_results.append(results)\n",
    "    sum_results = [0] * len(total_results[0])\n",
    "    for i in range(len(total_results)):\n",
    "        for j in range(len(total_results[0])):\n",
    "            sum_results[j] += total_results[i][j]\n",
    "    for i in range(len(total_results[0])):\n",
    "        sum_results[i] /= len(total_results)\n",
    "    G_K = [math.log(sum_results[i]) - math.log(results_simulation[i]) for i in range(len(results_simulation))]\n",
    "    maximum_k_value = max(G_K)\n",
    "    for i in range(20):\n",
    "        if G_K[i] == maximum_k_value:\n",
    "            return i + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 4\n",
      "The best k is 1\n",
      "The best k is 1\n",
      "The best k is 1\n",
      "The best k is 1\n",
      "The best k is 1\n",
      "The best k is 1\n",
      "The best k is 1\n",
      "The best k is 1\n",
      "The best k is 1\n"
     ]
    }
   ],
   "source": [
    "# It can take some minutes or hours\n",
    "sigmas = np.arange(0.05, 0.30, 0.01)\n",
    "max_k = []\n",
    "for sigma in sigmas:\n",
    "    maximum_k_sigma = maximum_k(sigma)\n",
    "    print(\"The best k is {0}\".format(maximum_k_sigma))\n",
    "    max_k.append(maximum_k_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Chosen K\")\n",
    "plt.xlabel(\"Sigma\")\n",
    "plt.ylabel(\"K\")\n",
    "plt.ylim([0, 5])\n",
    "plt.plot(sigmas, max_k, color='black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
